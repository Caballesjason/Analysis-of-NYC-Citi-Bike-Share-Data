{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2878a94c-28c6-4333-9868-93396f97dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- LIBRARY IMPORTS ----\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4f185f02-ef04-43ad-9f06-0dd20b58eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reading in datasets ----\n",
    "usecols = [index for index in range(1, 14)]\n",
    "dtype = {'ride_id': \"string\", 'rideable_type': \"string\", 'started_at': \"string\", 'ended_at': \"string\", 'start_station_name': \"string\",\n",
    "         'start_station_id': \"string\", 'end_station_name': \"string\", 'end_station_id': \"string\", 'start_lat': float,\n",
    "         'start_lng': float, 'end_lat': float, 'end_lng': float, 'member_casual': \"string\"}\n",
    "df = pd.read_csv('data/202407-citibike-tripdata_5.csv', usecols=usecols, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d987c-3c6a-4ec1-ae14-cd2253d74ea8",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "The following operations are required for data cleaning\n",
    "\n",
    "1. Encode `rideable_type` and `member_casual`\n",
    "2. Index `start_station_id` and `end_station_id`\n",
    "3. Create fields for `start_date`, `start_time`, `end_date`, `end_time`\n",
    "4. Create field for trip duration\n",
    "5. create network data structure using `networkx`\n",
    "6. Create distance between stations using the [Manhattan's Distance](https://www.datacamp.com/tutorial/manhattan-distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94eaf2-3fad-4626-8b1b-d14b01863782",
   "metadata": {},
   "source": [
    "## Encoding Binary Variables\n",
    "The `rideable_type` and `member_casual` fields will use dummy encoding using pandas' [`get_dummies`](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c6ae3f97-5b90-44f2-b70f-24cf11588649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data=df, columns=['rideable_type', 'member_casual'], dtype=\"int\", drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f9e6a-750c-4aad-a7b5-1819c4ef9fc3",
   "metadata": {},
   "source": [
    "## Indexing Stations\n",
    "We want to index station IDs so that we can have unique identifiers for them.  This will allow us to create nodes for our network data structure.  We need to first get a dictionary of all of the station IDs where the keys are the station IDs and the values are their indexes, then map their indexes in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "851e83ad-3229-4c54-937b-d5632d89fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dict of unique station IDs\n",
    "start_stations = df['start_station_id']\n",
    "end_stations = df['end_station_id']\n",
    "all_stations = pd.concat([start_stations, end_stations], axis=0).drop_duplicates(ignore_index=True)\n",
    "station_dict = {value: index for index, value in all_stations.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6311c11f-02c6-44be-bb1a-beb7759d5133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
